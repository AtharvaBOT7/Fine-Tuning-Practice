{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mwTXpnY5WrM-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "Q-fUCKQcWuqW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCXE9ZwdWutC",
        "outputId": "144e2109-b9e7-42de-f5d9-35631b600c8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 4.96MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 129kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.23MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.87MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TeacherMLP(nn.Module):\n",
        "  def __init__(self, hidden1=512, hidden2=256):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(28*28, hidden1),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden1,hidden2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden2,10)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "Ozp-IlQnWuvl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher = TeacherMLP(hidden1=512, hidden2=256)"
      ],
      "metadata": {
        "id": "y8DbNVoDWuxt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQW0YpALWu0G",
        "outputId": "93a7c498-f243-40db-8cbe-f8c83e528887"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TeacherMLP(\n",
              "  (net): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_teacher(model, loader, epochs=1, lr=1e-3):\n",
        "\n",
        "  opt = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for ep in range(epochs):\n",
        "    total_loss = 0\n",
        "    for x,y in loader:\n",
        "      opt.zero_grad()\n",
        "      out = model(x)\n",
        "      loss = loss_fn(out,y)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      total_loss += loss.item()\n",
        "  print(f\"Teacher Epoch: {ep} loss {total_loss}\")"
      ],
      "metadata": {
        "id": "cwdjkkdqWu20"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_teacher(teacher, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVMb_iXHWu5c",
        "outputId": "02776975-14f9-4687-f549-4974d3087d99"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Epoch: 0 loss 280.74651252664626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(teacher.state_dict()) # these are the updated weights of the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB-NfsfnWu79",
        "outputId": "8672d44b-3dd4-4cb1-f09e-168106abdccd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict({'net.1.weight': tensor([[ 0.0031, -0.0300, -0.0247,  ..., -0.0118, -0.0216, -0.0018],\n",
            "        [-0.0303,  0.0119,  0.0244,  ..., -0.0267,  0.0087,  0.0063],\n",
            "        [ 0.0218, -0.0121,  0.0245,  ...,  0.0248,  0.0027,  0.0077],\n",
            "        ...,\n",
            "        [ 0.0228,  0.0148,  0.0160,  ..., -0.0133, -0.0179, -0.0127],\n",
            "        [-0.0027, -0.0122, -0.0084,  ...,  0.0172,  0.0155,  0.0356],\n",
            "        [ 0.0256,  0.0028, -0.0232,  ...,  0.0194, -0.0161,  0.0202]]), 'net.1.bias': tensor([ 1.7872e-02,  3.7583e-03,  2.2602e-02,  9.3915e-03,  1.0925e-02,\n",
            "         2.4752e-02, -2.9046e-02, -3.2058e-02, -3.6937e-02, -1.6323e-02,\n",
            "         1.9877e-02, -6.8324e-03, -3.8924e-02,  5.7817e-03, -3.7199e-02,\n",
            "         1.2491e-02, -3.0926e-02, -3.4160e-02, -3.9047e-02,  2.5146e-02,\n",
            "         4.2276e-03,  1.3058e-02,  5.8560e-03, -1.7277e-02, -3.2338e-02,\n",
            "         2.4362e-02,  1.6240e-02,  1.6024e-02, -3.4222e-02, -1.9115e-02,\n",
            "        -2.6796e-02,  1.5300e-02,  2.1581e-02, -2.0665e-02, -3.3326e-02,\n",
            "         3.1391e-02, -2.7926e-02, -4.0352e-02,  3.0438e-03, -2.7720e-02,\n",
            "         1.7801e-02, -2.8235e-02,  5.8731e-03,  5.6564e-03,  1.7210e-02,\n",
            "        -3.2557e-02, -4.0391e-02, -2.4764e-02,  2.2380e-02,  4.4946e-03,\n",
            "         1.7829e-02,  8.9083e-03,  2.2390e-02, -3.3648e-02, -1.4232e-02,\n",
            "        -3.1284e-02, -2.3839e-02, -2.6137e-02, -2.3994e-02, -3.4252e-02,\n",
            "        -2.0141e-02,  1.5018e-02,  2.5786e-02, -2.5215e-02, -3.1130e-03,\n",
            "         4.3350e-03, -2.9137e-02, -3.8807e-02, -2.4291e-02, -2.3078e-02,\n",
            "         7.1734e-03, -3.0103e-02, -2.7824e-02, -1.2699e-02, -1.5188e-02,\n",
            "         6.3362e-03, -1.6294e-02,  2.1376e-02,  3.0555e-03, -6.2917e-03,\n",
            "        -1.1220e-02, -3.1682e-02,  3.1918e-02,  9.1599e-03,  1.6458e-02,\n",
            "        -1.7056e-02, -1.9325e-02, -3.8367e-03,  6.0930e-04,  9.7133e-03,\n",
            "         1.5671e-03,  1.5478e-02,  2.1588e-02, -2.5417e-02,  1.9333e-02,\n",
            "         2.8691e-02, -3.0646e-02, -1.8929e-02, -5.7065e-03,  4.0516e-03,\n",
            "         1.2441e-02, -3.4001e-02,  9.6472e-03, -5.4292e-03, -3.9769e-02,\n",
            "        -3.0871e-02,  3.1305e-02,  1.7167e-02,  3.0456e-02, -2.5962e-02,\n",
            "         2.5870e-02,  3.0340e-02,  1.8072e-02, -9.8698e-03, -1.9777e-02,\n",
            "         1.6910e-02,  3.3282e-02,  1.7999e-02, -1.8390e-02,  2.7043e-02,\n",
            "        -3.0719e-02,  1.1703e-02, -1.7981e-02,  2.2431e-03,  7.7973e-03,\n",
            "        -2.5515e-02,  1.2023e-02,  1.3812e-02, -2.8796e-02, -3.6716e-02,\n",
            "        -2.3333e-03,  2.6951e-02, -1.2526e-02,  2.2514e-02, -1.7949e-02,\n",
            "         1.6466e-02,  2.2213e-02, -3.0709e-02,  5.8267e-03,  2.5933e-02,\n",
            "        -1.9107e-02,  2.7248e-02, -1.9247e-02,  2.7773e-02, -2.2355e-02,\n",
            "        -6.8035e-03,  8.0418e-03,  2.5110e-02,  1.0939e-02, -1.9711e-02,\n",
            "        -2.2830e-02, -9.9629e-03, -3.2501e-02, -3.1281e-02,  2.1071e-02,\n",
            "         2.3800e-02,  1.7724e-02,  1.4296e-02,  2.0677e-02,  2.5304e-02,\n",
            "         2.2829e-03, -1.5538e-02, -2.8727e-02, -1.3106e-02,  1.6589e-02,\n",
            "         1.9613e-02, -2.9498e-02, -7.6963e-03,  6.4529e-03, -1.4390e-02,\n",
            "        -6.2467e-03,  1.9338e-02, -1.9579e-02, -1.7652e-02,  1.6216e-02,\n",
            "         3.0968e-02,  5.1766e-04, -1.9091e-02,  1.4567e-02,  3.4943e-02,\n",
            "         1.0149e-02, -7.8703e-03, -1.2644e-02,  4.8179e-03, -3.4791e-02,\n",
            "        -3.2957e-03, -2.0617e-02, -1.0378e-02, -3.4383e-02, -4.4657e-03,\n",
            "         2.1987e-02, -1.4757e-02,  6.3266e-03, -1.0096e-02, -2.4753e-02,\n",
            "         1.1811e-02,  2.0013e-02, -2.8925e-02,  2.0747e-02, -1.6265e-02,\n",
            "         1.3785e-02, -1.5664e-03,  2.8603e-02, -1.3639e-02,  1.7402e-02,\n",
            "        -1.4703e-02,  2.3685e-02, -1.5878e-02, -3.4697e-02, -2.6618e-03,\n",
            "        -2.7506e-02, -2.6827e-02, -1.7191e-02, -1.2789e-02, -1.2987e-02,\n",
            "         1.5826e-02, -6.0925e-03,  1.0756e-02,  1.1262e-02,  1.6889e-02,\n",
            "        -2.3482e-02,  3.1007e-02,  1.5127e-02,  2.0626e-02,  1.5467e-02,\n",
            "         2.5877e-02,  6.6932e-03, -2.3956e-02,  3.2512e-02, -2.9019e-02,\n",
            "         1.3611e-02, -6.3048e-03,  5.3388e-03, -2.6126e-02,  1.6691e-02,\n",
            "         5.8357e-03, -3.2293e-02, -1.6528e-02,  1.7599e-02,  1.0347e-02,\n",
            "        -7.3902e-04, -2.9074e-02, -2.2158e-03, -3.5491e-02,  1.9414e-02,\n",
            "         2.3330e-02, -2.0799e-02, -1.8524e-02, -9.2203e-05, -1.6050e-02,\n",
            "         1.1918e-02, -3.5374e-02, -2.7575e-02, -5.1200e-03,  2.1233e-02,\n",
            "        -2.9556e-04, -2.8257e-03,  3.5122e-03,  2.5297e-02,  1.7213e-02,\n",
            "         1.6708e-02, -2.5438e-02,  4.8780e-03, -2.8166e-02, -2.5035e-02,\n",
            "        -1.2592e-02, -9.0904e-03,  3.4985e-02, -3.6731e-02, -1.1792e-02,\n",
            "         2.8720e-02,  2.7391e-02,  2.6810e-02, -2.2540e-02, -2.6820e-02,\n",
            "        -5.1048e-03, -3.8446e-02,  2.1048e-02,  6.4183e-03,  2.5730e-03,\n",
            "         8.0183e-03, -2.3517e-02,  1.4750e-02,  2.0112e-02, -7.0555e-03,\n",
            "        -1.9694e-02, -6.6206e-04,  2.2836e-02,  3.9348e-02,  2.6386e-02,\n",
            "         5.3681e-03, -2.4798e-02, -1.1004e-02,  1.0226e-02, -2.3588e-02,\n",
            "        -1.7495e-02, -6.0873e-03,  2.3453e-02, -6.7920e-03,  2.6638e-02,\n",
            "         2.4745e-02,  3.6694e-02,  1.5317e-03, -1.9671e-02, -2.8127e-02,\n",
            "        -2.6605e-02, -2.2292e-02, -2.3058e-02, -5.1100e-03,  1.4042e-02,\n",
            "        -4.1897e-03, -2.2717e-03,  1.2364e-02,  2.5544e-02,  1.4514e-02,\n",
            "        -1.7638e-02,  1.1242e-02, -3.5022e-02, -3.6199e-02, -8.0280e-03,\n",
            "         7.0281e-03,  1.4147e-02,  6.7676e-03, -2.2777e-02, -7.1584e-03,\n",
            "        -1.9086e-02, -2.0319e-02,  4.2228e-04,  3.5160e-02,  2.9591e-02,\n",
            "         3.6165e-02,  8.7308e-03, -2.4999e-02, -4.5396e-03,  2.0066e-02,\n",
            "         3.1128e-03, -2.9749e-02, -1.6894e-02,  1.7818e-02,  7.7314e-04,\n",
            "        -4.0866e-02, -2.8255e-02, -8.5690e-03,  2.1501e-03,  2.9418e-02,\n",
            "         5.4165e-03,  3.5649e-03, -1.7769e-02,  9.3960e-03,  6.3574e-03,\n",
            "        -1.2296e-02, -5.0259e-03, -3.4872e-02, -2.5742e-02,  3.9122e-02,\n",
            "        -3.3921e-02,  1.8185e-02,  3.7628e-03, -2.0588e-02, -2.6731e-02,\n",
            "        -2.1107e-02, -2.4130e-02, -1.4631e-02, -2.4170e-03, -3.0897e-02,\n",
            "        -4.4259e-02,  8.3029e-03, -4.3463e-03, -1.9199e-02,  2.3196e-02,\n",
            "        -1.8662e-02, -1.5466e-02, -3.3997e-02, -3.4943e-02, -1.5330e-02,\n",
            "        -4.3810e-02,  1.6444e-02,  4.3073e-02, -4.0178e-02,  3.7110e-03,\n",
            "         1.2093e-02,  2.4259e-02, -1.5703e-02,  1.8281e-02, -8.8055e-03,\n",
            "         2.4490e-02,  1.3391e-02,  2.9615e-02,  1.1256e-02, -1.2998e-02,\n",
            "        -3.4142e-02,  1.8432e-02,  1.0318e-03,  1.7113e-02, -1.3860e-03,\n",
            "         2.4985e-02, -3.8187e-02, -3.9498e-03,  5.9640e-03, -2.1678e-02,\n",
            "        -1.8086e-02,  6.5747e-03,  1.2996e-02, -1.0933e-02, -1.8640e-02,\n",
            "         2.3397e-02, -2.8262e-02, -3.1424e-02, -6.4917e-03, -2.3033e-02,\n",
            "        -3.6005e-02, -5.4084e-03, -1.9159e-02, -1.7679e-03,  1.3982e-02,\n",
            "         1.8207e-02,  1.6804e-02,  3.7234e-02,  5.8332e-03, -1.8004e-02,\n",
            "        -3.5214e-04, -1.9809e-02, -1.5193e-02,  2.3358e-02, -3.1196e-02,\n",
            "        -1.1204e-02, -2.8275e-02,  3.0821e-02, -3.9867e-03,  6.7850e-03,\n",
            "         1.7717e-02,  1.2790e-02, -6.9773e-03, -1.3944e-03, -2.0825e-02,\n",
            "         7.1028e-03, -1.2405e-02, -6.6183e-03, -1.0090e-02, -1.1014e-03,\n",
            "         1.6187e-02,  2.0281e-02, -2.6249e-02, -2.2068e-02, -7.3130e-03,\n",
            "         1.8389e-02,  2.2808e-02,  2.9515e-02,  1.1980e-02,  2.9664e-03,\n",
            "        -4.7189e-03, -3.8065e-02,  2.0371e-02,  1.8774e-02, -4.5890e-03,\n",
            "        -3.2805e-02, -3.9311e-02, -3.3947e-02,  1.3645e-02,  2.9522e-02,\n",
            "        -4.1815e-02, -7.4731e-03, -1.2611e-03, -1.3088e-03, -1.0336e-02,\n",
            "        -2.4558e-03,  8.6677e-03, -7.9101e-03,  2.5435e-02, -2.9750e-02,\n",
            "        -8.0157e-03, -3.2222e-02, -3.3278e-02,  9.1055e-03, -2.9876e-02,\n",
            "        -1.9937e-03,  3.7233e-02, -2.8991e-02, -2.9648e-02, -1.3904e-02,\n",
            "        -9.2968e-03, -2.7878e-03,  1.3946e-02, -3.4784e-02, -2.6354e-02,\n",
            "         6.0829e-05, -7.8936e-03, -1.0474e-02, -7.9454e-03,  2.3549e-02,\n",
            "        -1.5092e-02, -1.6812e-02, -3.1663e-02,  3.8846e-03,  2.2568e-02,\n",
            "         6.2762e-03, -3.2152e-02,  3.1666e-02, -3.2874e-03, -1.6714e-02,\n",
            "         2.6165e-02,  2.5225e-02,  2.9565e-02,  3.7773e-03,  6.2780e-03,\n",
            "        -3.4530e-02, -1.4320e-02, -1.4164e-02,  2.6136e-02, -3.2550e-03,\n",
            "         1.1238e-02,  1.4263e-02]), 'net.3.weight': tensor([[-0.0255, -0.0639,  0.0208,  ...,  0.0470,  0.0256,  0.0004],\n",
            "        [ 0.0119, -0.0385, -0.0246,  ...,  0.0061, -0.0321,  0.0146],\n",
            "        [ 0.0048, -0.0257,  0.0298,  ..., -0.0105,  0.0290,  0.0022],\n",
            "        ...,\n",
            "        [-0.0078,  0.0040,  0.0224,  ..., -0.0671,  0.0256, -0.0576],\n",
            "        [-0.0531, -0.0121, -0.0399,  ...,  0.0786,  0.0266,  0.0063],\n",
            "        [ 0.0237,  0.0312, -0.0126,  ...,  0.0019, -0.0382,  0.0138]]), 'net.3.bias': tensor([-2.1344e-02, -8.5279e-03, -2.2743e-02, -3.1577e-03,  4.3215e-02,\n",
            "         3.5715e-02,  2.4314e-02,  2.0861e-02,  1.9103e-02,  6.0727e-03,\n",
            "         7.2069e-03,  1.2475e-02, -2.8382e-02, -4.7666e-02,  1.7360e-02,\n",
            "         3.8600e-02,  3.4255e-02,  2.8468e-03, -6.1197e-02,  1.5217e-02,\n",
            "        -4.2613e-02, -1.2896e-02,  5.4387e-02,  7.4451e-03, -1.6171e-02,\n",
            "        -2.6979e-02,  5.6328e-02,  4.2198e-02,  2.7966e-02,  2.1549e-02,\n",
            "        -4.3253e-02, -1.2482e-02,  1.2288e-02,  2.0536e-02, -4.2732e-02,\n",
            "         2.5702e-03, -3.3784e-02,  7.6530e-03, -1.8752e-02, -5.0841e-03,\n",
            "        -3.9318e-03, -3.6410e-02, -4.1570e-02,  5.1524e-03, -4.2562e-02,\n",
            "        -1.4472e-04, -4.0665e-02, -2.3126e-02, -1.2424e-02, -1.2041e-02,\n",
            "        -2.6537e-02,  3.3865e-03, -3.1985e-02,  2.0071e-02, -6.1683e-02,\n",
            "         1.8437e-02,  3.3381e-02,  1.5263e-02, -2.9654e-02,  2.5350e-02,\n",
            "        -3.6416e-02, -8.2095e-03,  2.1405e-02, -5.6466e-02,  1.8553e-02,\n",
            "        -4.1155e-02,  1.1267e-02, -3.2897e-02, -1.8565e-02, -1.2002e-02,\n",
            "         3.5064e-03,  9.7241e-03,  2.0987e-02, -8.4391e-03, -2.7406e-02,\n",
            "        -2.6118e-02,  3.8750e-02,  5.2109e-02, -3.9016e-02,  2.4777e-02,\n",
            "         5.3420e-03,  3.5177e-02, -7.9575e-03, -5.6335e-02, -4.3609e-02,\n",
            "        -2.6739e-02,  5.7625e-02,  6.8240e-03, -1.0078e-02,  1.5721e-02,\n",
            "        -1.7236e-02,  3.3295e-02, -4.0143e-02,  1.3586e-02, -2.5749e-02,\n",
            "         3.2898e-02,  2.5692e-02, -3.9842e-02, -3.3038e-02, -2.4930e-04,\n",
            "        -1.4321e-02, -5.2472e-02,  6.9794e-05,  1.3792e-02,  1.9186e-02,\n",
            "        -1.2116e-02,  6.9884e-03, -2.5237e-02, -1.3603e-02, -4.7896e-02,\n",
            "         2.4162e-02,  1.1499e-02,  3.5514e-03,  2.3633e-03, -2.7924e-02,\n",
            "        -2.1978e-02,  2.7856e-03, -1.0758e-02,  9.4889e-03, -6.5471e-02,\n",
            "         1.4468e-02,  2.6538e-02,  2.6833e-02,  6.2806e-03,  1.7857e-02,\n",
            "        -4.1931e-02,  4.2366e-02, -2.6073e-02, -5.4822e-02, -3.1886e-02,\n",
            "        -3.1851e-02, -1.4541e-02, -6.1865e-03,  1.0367e-02, -2.6274e-02,\n",
            "        -7.5245e-03, -3.6796e-02, -1.8914e-02, -6.0397e-02,  3.4272e-02,\n",
            "         3.0323e-02,  5.3325e-03,  3.3252e-02, -2.5539e-02,  9.3025e-03,\n",
            "        -2.3698e-02,  5.7415e-03,  1.8863e-02, -1.3998e-02, -1.7652e-02,\n",
            "        -3.3620e-02, -2.2336e-02, -1.5220e-02, -2.2151e-02,  1.9023e-02,\n",
            "         1.7395e-02,  2.2717e-02, -2.1189e-02,  3.8379e-02,  3.4766e-02,\n",
            "        -4.0616e-02,  2.8002e-03,  8.9438e-03, -1.3236e-02,  2.1337e-02,\n",
            "        -1.4982e-02,  2.4243e-02, -2.4313e-02,  5.4862e-02, -2.0311e-02,\n",
            "         1.4393e-02, -4.3893e-02,  3.6641e-02, -5.4444e-03,  5.2928e-04,\n",
            "        -1.6636e-02,  2.4653e-02,  1.3987e-02, -4.5772e-02,  6.5606e-03,\n",
            "         8.6433e-03, -7.4521e-03, -1.1170e-02, -2.4881e-02, -5.4662e-02,\n",
            "         1.3237e-04,  2.1004e-02, -4.0035e-02,  3.2299e-02,  5.3218e-02,\n",
            "        -5.9089e-02, -2.2653e-02, -5.6155e-02, -1.2530e-03, -9.7011e-03,\n",
            "        -3.6769e-02, -3.0746e-02,  2.7494e-02,  5.1283e-02,  1.8959e-02,\n",
            "        -1.1815e-02,  4.0908e-02, -4.0537e-02,  3.6434e-02, -2.0960e-02,\n",
            "        -3.4534e-02,  3.0047e-02, -5.3261e-03, -5.1095e-02,  5.2668e-02,\n",
            "         1.5314e-02,  3.6896e-02, -2.8965e-02, -4.0756e-02,  6.1982e-02,\n",
            "        -4.3911e-02,  4.8887e-03, -3.8911e-02,  2.7707e-02,  1.3486e-02,\n",
            "        -2.1715e-03, -3.7625e-02, -1.9983e-02,  3.2906e-02, -3.6169e-02,\n",
            "        -1.8755e-02, -2.9256e-03,  1.8329e-02,  6.5455e-03, -3.3009e-02,\n",
            "        -1.8733e-02,  8.6908e-03, -4.5041e-02,  2.1995e-02, -3.0879e-02,\n",
            "         4.6330e-03, -2.0786e-03,  3.9050e-02,  2.4515e-02, -2.0271e-02,\n",
            "         1.3192e-03, -3.3034e-02,  2.8292e-02, -2.0266e-02,  4.5832e-04,\n",
            "         2.0658e-02, -4.7246e-02, -2.4334e-02,  7.6880e-03, -7.0613e-03,\n",
            "        -9.4681e-03, -2.4223e-02,  6.1318e-03, -2.2319e-03,  3.9893e-03,\n",
            "         1.6430e-02]), 'net.5.weight': tensor([[ 0.0247,  0.0075,  0.0642,  ...,  0.0217, -0.0437, -0.1082],\n",
            "        [-0.0740,  0.0640, -0.0736,  ..., -0.0163, -0.0220, -0.0084],\n",
            "        [ 0.0540, -0.0485,  0.0146,  ..., -0.0159, -0.0206, -0.0504],\n",
            "        ...,\n",
            "        [ 0.0459,  0.0642,  0.0625,  ...,  0.0555, -0.0636, -0.0092],\n",
            "        [ 0.0018, -0.0705,  0.0205,  ...,  0.0374, -0.0062,  0.0446],\n",
            "        [-0.0656, -0.0213, -0.0515,  ..., -0.0336, -0.0896,  0.0282]]), 'net.5.bias': tensor([-0.0294, -0.0687, -0.0195,  0.0364,  0.0517, -0.0585,  0.0467, -0.0394,\n",
            "         0.0408,  0.0079])})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StudentMLP(nn.Module):\n",
        "  def __init__(self, hidden=128):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(28*28, hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden,10)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "4yoUNCSEWu-M"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student = StudentMLP(hidden=128)"
      ],
      "metadata": {
        "id": "J7sxzpW6WvAq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(student)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM2WRnoJWvDU",
        "outputId": "7239c994-2237-446c-c167-57b684cf8ae9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StudentMLP(\n",
            "  (net): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have the untrained student model, so what we will do is we will take the soft labels from the teacher model and then use the hard labels of the student model."
      ],
      "metadata": {
        "id": "xqNj9_Yzdz9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distil Training"
      ],
      "metadata": {
        "id": "9E98PqpjeM6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperature = 2.0\n",
        "alpha = 0.7\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "optimizer = optim.Adam(student.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "5DZBv4wwWvFp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distil(student, teacher, loader, epochs=1):\n",
        "  for ep in range(epochs):\n",
        "\n",
        "    student.train() # This will not start the model training, this will just initialise the training.\n",
        "\n",
        "    total_loss = 0 # We will calculate this later\n",
        "\n",
        "    # Teacher model outputs\n",
        "    for x,y in loader: # Here x is the 1d array and y is the ground truth\n",
        "      with torch.no_grad():  # Torch.no_grad means that we are not going to update the teacher models gradients, this means we are not going to train the model.\n",
        "        t_logits = teacher(x)\n",
        "        t_probs = torch.softmax(t_logits / temperature, dim=1)\n",
        "\n",
        "    # Student model outputs\n",
        "      s_logits = student(x)\n",
        "      s_log_probs = torch.log_softmax(s_logits / temperature, dim=1)\n",
        "\n",
        "      # Calculating the Losses\n",
        "      loss_soft = kl_loss(s_log_probs, t_probs) * (temperature ** 2)\n",
        "      loss_hard = ce_loss(s_logits, y)\n",
        "      loss = alpha * loss_soft + (1 - alpha) * loss_hard\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss += loss.item()\n",
        "    print(f\" Student Epoch {ep} Loss {total_loss/len(loader):.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GcZwQ6lnWvIO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distil(student,teacher,train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEkL5h1nWvK1",
        "outputId": "6dc08405-c12f-4edb-8533-dd0493abdc73"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Student Epoch 0 Loss 0.5280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the performances of the teacher and student models"
      ],
      "metadata": {
        "id": "gHlREhawgp9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, name=\"Model\"):\n",
        "  model.eval()\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x,y in loader:\n",
        "      out = model(x)\n",
        "      preds = out.argmax(dim=1)\n",
        "      correct += (preds == y).sum().item()\n",
        "      total += y.size(0)\n",
        "  acc = correct / total * 100\n",
        "\n",
        "  print(f\"{name} Accuracy: {acc:.2f}%\")\n",
        "  return acc"
      ],
      "metadata": {
        "id": "BhYAu9uQWvNS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(teacher, test_loader, \"Teacher\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBu8VWDgWvQC",
        "outputId": "213f4db0-bd73-4e2a-a429-cae2eeafdfd7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Accuracy: 95.25%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95.25"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(student, test_loader, \"Student\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQFR0vFhhGLW",
        "outputId": "d0224018-2b13-491a-abf6-6a385467f170"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Accuracy: 92.54%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92.54"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here we can see that the student model's performance is near to the teacher model and in real world cases where performance matters more than the accuracy of the result the student model outshines the teacher model as it is a smaller model than the teacher model and thus is much faster."
      ],
      "metadata": {
        "id": "uYgNqRIOhKkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Predictions"
      ],
      "metadata": {
        "id": "LP5WcuG2hqy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, x):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    out = model(x)\n",
        "    return out.argmax(dim=1)\n",
        ""
      ],
      "metadata": {
        "id": "_VRqcu9YhIZW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_batch, sample_labels = next(iter(test_loader))"
      ],
      "metadata": {
        "id": "sbTgIPQJhtOH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = predict(student, sample_batch)"
      ],
      "metadata": {
        "id": "r-jNLehPhtQT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Student Predictions: \", preds[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up41C4QbhtTT",
        "outputId": "b1375ffa-5f0b-408f-a4e8-419d6c7552f9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Predictions:  tensor([7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"True Labels: \", sample_labels[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH6wW5dUhtVQ",
        "outputId": "9422005e-6c03-429e-945d-efeb02806cdf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Labels:  tensor([7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6cdmWXkqhtW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3mUdnjwDhtYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vpP6QAdjhtiI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}