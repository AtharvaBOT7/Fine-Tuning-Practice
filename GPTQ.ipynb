{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e8205a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pip 25.2 from /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/pip (python 3.11)\n",
      "Collecting gptqmodel\n",
      "  Downloading gptqmodel-4.2.5.tar.gz (331 kB)\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l  Running command Preparing metadata (pyproject.toml)\n",
      "  CUDA None\n",
      "  HAS_CUDA_V8 False\n",
      "  SETUP_KWARGS {}\n",
      "  running dist_info\n",
      "  creating /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-modern-metadata-sbozxx1r/gptqmodel.egg-info\n",
      "  writing /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-modern-metadata-sbozxx1r/gptqmodel.egg-info/PKG-INFO\n",
      "  writing dependency_links to /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-modern-metadata-sbozxx1r/gptqmodel.egg-info/dependency_links.txt\n",
      "  writing requirements to /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-modern-metadata-sbozxx1r/gptqmodel.egg-info/requires.txt\n",
      "  writing top-level names to /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-modern-metadata-sbozxx1r/gptqmodel.egg-info/top_level.txt\n",
      "  writing manifest file '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-modern-metadata-sbozxx1r/gptqmodel.egg-info/SOURCES.txt'\n",
      "  reading manifest file '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-modern-metadata-sbozxx1r/gptqmodel.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  no previously-included directories found matching 'tests'\n",
      "  no previously-included directories found matching 'format'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-modern-metadata-sbozxx1r/gptqmodel.egg-info/SOURCES.txt'\n",
      "  creating '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-modern-metadata-sbozxx1r/gptqmodel-4.2.5.dist-info'\n",
      "\u001b[?25hdone\n",
      "Collecting accelerate>=1.10.1 (from gptqmodel)\n",
      "  Obtaining dependency information for accelerate>=1.10.1 from https://files.pythonhosted.org/packages/77/85/85951bc0f9843e2c10baaa1b6657227056095de08f4d1eea7d8b423a6832/accelerate-1.11.0-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=2.2.6 in ./gptq/lib/python3.11/site-packages (from gptqmodel) (2.3.4)\n",
      "Requirement already satisfied: torch>=2.8.0 in ./gptq/lib/python3.11/site-packages (from gptqmodel) (2.9.0)\n",
      "Requirement already satisfied: safetensors>=0.6.2 in ./gptq/lib/python3.11/site-packages (from gptqmodel) (0.6.2)\n",
      "Requirement already satisfied: transformers>=4.56.0 in ./gptq/lib/python3.11/site-packages (from gptqmodel) (4.57.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.6.0 in ./gptq/lib/python3.11/site-packages (from gptqmodel) (3.6.0)\n",
      "Requirement already satisfied: packaging>=24.2 in ./gptq/lib/python3.11/site-packages (from gptqmodel) (25.0)\n",
      "Collecting device-smi==0.4.1 (from gptqmodel)\n",
      "  Downloading device_smi-0.4.1.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l  Running command python setup.py egg_info\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/_distutils/dist.py:289: UserWarning: Unknown distribution option: 'platform'\n",
      "    warnings.warn(msg)\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  !!\n",
      "\n",
      "          ********************************************************************************\n",
      "          Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "\n",
      "          License :: OSI Approved :: Apache Software License\n",
      "\n",
      "          See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "          ********************************************************************************\n",
      "\n",
      "  !!\n",
      "    self._finalize_license_expression()\n",
      "  running egg_info\n",
      "  creating /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-dxztk4uq/device_smi.egg-info\n",
      "  writing /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-dxztk4uq/device_smi.egg-info/PKG-INFO\n",
      "  writing dependency_links to /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-dxztk4uq/device_smi.egg-info/dependency_links.txt\n",
      "  writing top-level names to /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-dxztk4uq/device_smi.egg-info/top_level.txt\n",
      "  writing manifest file '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-dxztk4uq/device_smi.egg-info/SOURCES.txt'\n",
      "  reading manifest file '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-dxztk4uq/device_smi.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-dxztk4uq/device_smi.egg-info/SOURCES.txt'\n",
      "\u001b[?25hdone\n",
      "Collecting protobuf>=6.32.0 (from gptqmodel)\n",
      "  Obtaining dependency information for protobuf>=6.32.0 from https://files.pythonhosted.org/packages/e1/a9/b6eee662a6951b9c3640e8e452ab3e09f117d99fc10baa32d1581a0d4099/protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting pillow>=11.3.0 (from gptqmodel)\n",
      "  Obtaining dependency information for pillow>=11.3.0 from https://files.pythonhosted.org/packages/2e/05/069b1f8a2e4b5a37493da6c5868531c3f77b85e716ad7a590ef87d58730d/pillow-12.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pillow-12.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting hf_transfer>=0.1.9 (from gptqmodel)\n",
      "  Obtaining dependency information for hf_transfer>=0.1.9 from https://files.pythonhosted.org/packages/41/ba/8d9fd9f1083525edfcb389c93738c802f3559cb749324090d7109c8bf4c2/hf_transfer-0.1.9-cp38-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-macosx_11_0_arm64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.4 in ./gptq/lib/python3.11/site-packages (from gptqmodel) (0.36.0)\n",
      "Collecting random_word==1.0.13 (from gptqmodel)\n",
      "  Obtaining dependency information for random_word==1.0.13 from https://files.pythonhosted.org/packages/df/46/3ce7166b6f99e61fab286d807bf8834cb8e23adbc1becff047b37c9cd666/random_word-1.0.13-py3-none-any.whl.metadata\n",
      "  Downloading random_word-1.0.13-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting tokenicer>=0.0.5 (from gptqmodel)\n",
      "  Downloading tokenicer-0.0.5.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l  Running command python setup.py egg_info\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/_distutils/dist.py:289: UserWarning: Unknown distribution option: 'platform'\n",
      "    warnings.warn(msg)\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  !!\n",
      "\n",
      "          ********************************************************************************\n",
      "          Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "\n",
      "          License :: OSI Approved :: Apache Software License\n",
      "\n",
      "          See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "          ********************************************************************************\n",
      "\n",
      "  !!\n",
      "    self._finalize_license_expression()\n",
      "  running egg_info\n",
      "  creating /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-_kp6fqlo/tokenicer.egg-info\n",
      "  writing /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-_kp6fqlo/tokenicer.egg-info/PKG-INFO\n",
      "  writing dependency_links to /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-_kp6fqlo/tokenicer.egg-info/dependency_links.txt\n",
      "  writing requirements to /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-_kp6fqlo/tokenicer.egg-info/requires.txt\n",
      "  writing top-level names to /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-_kp6fqlo/tokenicer.egg-info/top_level.txt\n",
      "  writing manifest file '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-_kp6fqlo/tokenicer.egg-info/SOURCES.txt'\n",
      "  reading manifest file '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-_kp6fqlo/tokenicer.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  no previously-included directories found matching 'tests'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-_kp6fqlo/tokenicer.egg-info/SOURCES.txt'\n",
      "\u001b[?25hdone\n",
      "Collecting logbar==0.0.4 (from gptqmodel)\n",
      "  Downloading logbar-0.0.4.tar.gz (12 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l  Running command python setup.py egg_info\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/_distutils/dist.py:289: UserWarning: Unknown distribution option: 'platform'\n",
      "    warnings.warn(msg)\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  !!\n",
      "\n",
      "          ********************************************************************************\n",
      "          Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "\n",
      "          License :: OSI Approved :: Apache Software License\n",
      "\n",
      "          See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "          ********************************************************************************\n",
      "\n",
      "  !!\n",
      "    self._finalize_license_expression()\n",
      "  running egg_info\n",
      "  creating /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-goi7mpjx/logbar.egg-info\n",
      "  writing /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-goi7mpjx/logbar.egg-info/PKG-INFO\n",
      "  writing dependency_links to /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-goi7mpjx/logbar.egg-info/dependency_links.txt\n",
      "  writing top-level names to /private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-goi7mpjx/logbar.egg-info/top_level.txt\n",
      "  writing manifest file '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-goi7mpjx/logbar.egg-info/SOURCES.txt'\n",
      "  reading manifest file '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-goi7mpjx/logbar.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  no previously-included directories found matching 'tests'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-pip-egg-info-goi7mpjx/logbar.egg-info/SOURCES.txt'\n",
      "\u001b[?25hdone\n",
      "Requirement already satisfied: wheel>=0.45.1 in ./gptq/lib/python3.11/site-packages (from gptqmodel) (0.45.1)\n",
      "Collecting maturin>=1.9.3 (from gptqmodel)\n",
      "  Obtaining dependency information for maturin>=1.9.3 from https://files.pythonhosted.org/packages/4d/1c/8e58eda6601f328b412cdeeaa88a9b6a10e591e2a73f313e8c0154d68385/maturin-1.9.6-py3-none-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata\n",
      "  Downloading maturin-1.9.6-py3-none-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (16 kB)\n",
      "Collecting autopep8<3.0.0,>=2.3.1 (from random_word==1.0.13->gptqmodel)\n",
      "  Obtaining dependency information for autopep8<3.0.0,>=2.3.1 from https://files.pythonhosted.org/packages/9e/43/53afb8ba17218f19b77c7834128566c5bbb100a0ad9ba2e8e89d089d7079/autopep8-2.3.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading autopep8-2.3.2-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pytest<9.0.0,>=8.3.3 (from random_word==1.0.13->gptqmodel)\n",
      "  Obtaining dependency information for pytest<9.0.0,>=8.3.3 from https://files.pythonhosted.org/packages/a8/a4/20da314d277121d6534b3a980b29035dcd51e6744bd79075a6ce8fa4eb8d/pytest-8.4.2-py3-none-any.whl.metadata\n",
      "  Downloading pytest-8.4.2-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in ./gptq/lib/python3.11/site-packages (from random_word==1.0.13->gptqmodel) (6.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in ./gptq/lib/python3.11/site-packages (from random_word==1.0.13->gptqmodel) (2.32.5)\n",
      "Collecting pycodestyle>=2.12.0 (from autopep8<3.0.0,>=2.3.1->random_word==1.0.13->gptqmodel)\n",
      "  Obtaining dependency information for pycodestyle>=2.12.0 from https://files.pythonhosted.org/packages/d7/27/a58ddaf8c588a3ef080db9d0b7e0b97215cee3a45df74f3a94dbbf5c893a/pycodestyle-2.14.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading pycodestyle-2.14.0-py2.py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting iniconfig>=1 (from pytest<9.0.0,>=8.3.3->random_word==1.0.13->gptqmodel)\n",
      "  Obtaining dependency information for iniconfig>=1 from https://files.pythonhosted.org/packages/cb/b1/3846dd7f199d53cb17f49cba7e651e9ce294d8497c8c150530ed11865bb8/iniconfig-2.3.0-py3-none-any.whl.metadata\n",
      "  Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest<9.0.0,>=8.3.3->random_word==1.0.13->gptqmodel)\n",
      "  Obtaining dependency information for pluggy<2,>=1.5 from https://files.pythonhosted.org/packages/54/20/4d324d65cc6d9205fabedc306948156824eb9f0ee1633355a8f7ec5c66bf/pluggy-1.6.0-py3-none-any.whl.metadata\n",
      "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: pygments>=2.7.2 in ./gptq/lib/python3.11/site-packages (from pytest<9.0.0,>=8.3.3->random_word==1.0.13->gptqmodel) (2.19.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./gptq/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.3->random_word==1.0.13->gptqmodel) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./gptq/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.3->random_word==1.0.13->gptqmodel) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./gptq/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.3->random_word==1.0.13->gptqmodel) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./gptq/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.3->random_word==1.0.13->gptqmodel) (2025.10.5)\n",
      "Requirement already satisfied: psutil in ./gptq/lib/python3.11/site-packages (from accelerate>=1.10.1->gptqmodel) (7.1.1)\n",
      "Requirement already satisfied: filelock in ./gptq/lib/python3.11/site-packages (from huggingface_hub>=0.34.4->gptqmodel) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./gptq/lib/python3.11/site-packages (from huggingface_hub>=0.34.4->gptqmodel) (2025.9.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./gptq/lib/python3.11/site-packages (from huggingface_hub>=0.34.4->gptqmodel) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./gptq/lib/python3.11/site-packages (from huggingface_hub>=0.34.4->gptqmodel) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./gptq/lib/python3.11/site-packages (from huggingface_hub>=0.34.4->gptqmodel) (1.1.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./gptq/lib/python3.11/site-packages (from torch>=2.8.0->gptqmodel) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./gptq/lib/python3.11/site-packages (from torch>=2.8.0->gptqmodel) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./gptq/lib/python3.11/site-packages (from torch>=2.8.0->gptqmodel) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./gptq/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.8.0->gptqmodel) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./gptq/lib/python3.11/site-packages (from transformers>=4.56.0->gptqmodel) (2025.10.23)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./gptq/lib/python3.11/site-packages (from transformers>=4.56.0->gptqmodel) (0.22.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./gptq/lib/python3.11/site-packages (from jinja2->torch>=2.8.0->gptqmodel) (3.0.3)\n",
      "Downloading random_word-1.0.13-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading autopep8-2.3.2-py2.py3-none-any.whl (45 kB)\n",
      "Downloading pytest-8.4.2-py3-none-any.whl (365 kB)\n",
      "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "Downloading hf_transfer-0.1.9-cp38-abi3-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading maturin-1.9.6-py3-none-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (15.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp311-cp311-macosx_11_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Downloading pycodestyle-2.14.0-py2.py3-none-any.whl (31 kB)\n",
      "Building wheels for collected packages: gptqmodel, device-smi, logbar, tokenicer\n",
      "  Building wheel for gptqmodel (pyproject.toml) ... \u001b[?25l  Running command Building wheel for gptqmodel (pyproject.toml)\n",
      "  CUDA None\n",
      "  HAS_CUDA_V8 False\n",
      "  SETUP_KWARGS {}\n",
      "  running bdist_wheel\n",
      "  Resolved wheel URL: https://github.com/ModelCloud/GPTQModel/releases/download/v4.2.5/gptqmodel-4.2.5+cpu-cp311-cp311-linux_x86_64.whl\n",
      "  wheel name=gptqmodel-4.2.5+cpu-cp311-cp311-linux_x86_64.whl\n",
      "  Precompiled wheel not found at: https://github.com/ModelCloud/GPTQModel/releases/download/v4.2.5/gptqmodel-4.2.5+cpu-cp311-cp311-linux_x86_64.whl. Building from source...\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build/lib/gptqmodel\n",
      "  copying gptqmodel/version.py -> build/lib/gptqmodel\n",
      "  copying gptqmodel/__init__.py -> build/lib/gptqmodel\n",
      "  creating build/lib/gptqmodel/nn_modules\n",
      "  copying gptqmodel/nn_modules/__init__.py -> build/lib/gptqmodel/nn_modules\n",
      "  copying gptqmodel/nn_modules/hooked_linear.py -> build/lib/gptqmodel/nn_modules\n",
      "  creating build/lib/gptqmodel/looper\n",
      "  copying gptqmodel/looper/native_processor.py -> build/lib/gptqmodel/looper\n",
      "  copying gptqmodel/looper/module_looper.py -> build/lib/gptqmodel/looper\n",
      "  copying gptqmodel/looper/qqq_processor.py -> build/lib/gptqmodel/looper\n",
      "  copying gptqmodel/looper/input_cache.py -> build/lib/gptqmodel/looper\n",
      "  copying gptqmodel/looper/__init__.py -> build/lib/gptqmodel/looper\n",
      "  copying gptqmodel/looper/gptq_processor.py -> build/lib/gptqmodel/looper\n",
      "  copying gptqmodel/looper/eora_processor.py -> build/lib/gptqmodel/looper\n",
      "  copying gptqmodel/looper/named_module.py -> build/lib/gptqmodel/looper\n",
      "  copying gptqmodel/looper/dequantize_processor.py -> build/lib/gptqmodel/looper\n",
      "  copying gptqmodel/looper/loop_processor.py -> build/lib/gptqmodel/looper\n",
      "  creating build/lib/gptqmodel/eora\n",
      "  copying gptqmodel/eora/eora.py -> build/lib/gptqmodel/eora\n",
      "  copying gptqmodel/eora/__init__.py -> build/lib/gptqmodel/eora\n",
      "  creating build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/rocm.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/marlin.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/bitblas.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/backend.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/vllm.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/importer.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/terminal.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/device.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/perplexity.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/__init__.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/mmlupro.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/logger.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/model.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/tensor.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/openai_server.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/vram.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/python.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/structure.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/eval.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/evalplus.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/torch.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/exllama.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/sglang.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/plotly.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/image.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/mlx.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/data.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/calibration.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/hf.py -> build/lib/gptqmodel/utils\n",
      "  copying gptqmodel/utils/safetensor.py -> build/lib/gptqmodel/utils\n",
      "  creating build/lib/gptqmodel/models\n",
      "  copying gptqmodel/models/__init__.py -> build/lib/gptqmodel/models\n",
      "  copying gptqmodel/models/_const.py -> build/lib/gptqmodel/models\n",
      "  copying gptqmodel/models/loader.py -> build/lib/gptqmodel/models\n",
      "  copying gptqmodel/models/writer.py -> build/lib/gptqmodel/models\n",
      "  copying gptqmodel/models/base.py -> build/lib/gptqmodel/models\n",
      "  copying gptqmodel/models/auto.py -> build/lib/gptqmodel/models\n",
      "  creating build/lib/gptqmodel/adapter\n",
      "  copying gptqmodel/adapter/remote.py -> build/lib/gptqmodel/adapter\n",
      "  copying gptqmodel/adapter/adapter.py -> build/lib/gptqmodel/adapter\n",
      "  copying gptqmodel/adapter/peft.py -> build/lib/gptqmodel/adapter\n",
      "  copying gptqmodel/adapter/__init__.py -> build/lib/gptqmodel/adapter\n",
      "  creating build/lib/gptqmodel/quantization\n",
      "  copying gptqmodel/quantization/gar.py -> build/lib/gptqmodel/quantization\n",
      "  copying gptqmodel/quantization/qqq.py -> build/lib/gptqmodel/quantization\n",
      "  copying gptqmodel/quantization/config.py -> build/lib/gptqmodel/quantization\n",
      "  copying gptqmodel/quantization/__init__.py -> build/lib/gptqmodel/quantization\n",
      "  copying gptqmodel/quantization/quantizer.py -> build/lib/gptqmodel/quantization\n",
      "  copying gptqmodel/quantization/gptqv2.py -> build/lib/gptqmodel/quantization\n",
      "  copying gptqmodel/quantization/gptq.py -> build/lib/gptqmodel/quantization\n",
      "  creating build/lib/gptqmodel/nn_modules/triton_utils\n",
      "  copying gptqmodel/nn_modules/triton_utils/mixin.py -> build/lib/gptqmodel/nn_modules/triton_utils\n",
      "  copying gptqmodel/nn_modules/triton_utils/custom_autotune.py -> build/lib/gptqmodel/nn_modules/triton_utils\n",
      "  copying gptqmodel/nn_modules/triton_utils/__init__.py -> build/lib/gptqmodel/nn_modules/triton_utils\n",
      "  copying gptqmodel/nn_modules/triton_utils/kernels.py -> build/lib/gptqmodel/nn_modules/triton_utils\n",
      "  copying gptqmodel/nn_modules/triton_utils/dequant.py -> build/lib/gptqmodel/nn_modules/triton_utils\n",
      "  creating build/lib/gptqmodel/nn_modules/qlinear\n",
      "  copying gptqmodel/nn_modules/qlinear/marlin.py -> build/lib/gptqmodel/nn_modules/qlinear\n",
      "  copying gptqmodel/nn_modules/qlinear/bitblas.py -> build/lib/gptqmodel/nn_modules/qlinear\n",
      "  copying gptqmodel/nn_modules/qlinear/qqq.py -> build/lib/gptqmodel/nn_modules/qlinear\n",
      "  copying gptqmodel/nn_modules/qlinear/tritonv2.py -> build/lib/gptqmodel/nn_modules/qlinear\n",
      "  copying gptqmodel/nn_modules/qlinear/torch_fused.py -> build/lib/gptqmodel/nn_modules/qlinear\n",
      "  copying gptqmodel/nn_modules/qlinear/exllamav2.py -> build/lib/gptqmodel/nn_modules/qlinear\n",
      "  copying gptqmodel/nn_modules/qlinear/exllama_eora.py -> build/lib/gptqmodel/nn_modules/qlinear\n",
      "  copying gptqmodel/nn_modules/qlinear/__init__.py -> build/lib/gptqmodel/nn_modules/qlinear\n",
      "  copying gptqmodel/nn_modules/qlinear/utils.py -> build/lib/gptqmodel/nn_modules/qlinear\n",
      "  copying gptqmodel/nn_modules/qlinear/ipex.py -> build/lib/gptqmodel/nn_modules/qlinear\n",
      "  copying gptqmodel/nn_modules/qlinear/torch.py -> build/lib/gptqmodel/nn_modules/qlinear\n",
      "  copying gptqmodel/nn_modules/qlinear/exllama.py -> build/lib/gptqmodel/nn_modules/qlinear\n",
      "  copying gptqmodel/nn_modules/qlinear/bitblas_target_detector.py -> build/lib/gptqmodel/nn_modules/qlinear\n",
      "  creating build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/instella.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/phi3.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/apertus.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/glm.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/dbrx.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/qwen2_vl.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/llama4.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/ovis.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/mistral.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/glm4_moe.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/olmo2.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/gpt2.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/base_qwen2_vl.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/qwen2_5_vl.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/llava_qwen2.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/chatglm.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/stablelmepoch.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/internlm2.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/mimo.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/nemotron_h.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/klear.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/gptj.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/__init__.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/dream.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/qwen3_moe.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/qwen2_5_omni.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/starcoder2.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/minicpm.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/ernie4_5.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/opt.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/kimi_k2.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/mllama.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/seed_oss.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/pangu_alpha.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/llama.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/gemma2.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/xverse.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/ernie4_5_moe.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/rw.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/cohere2.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/qwen.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/gemma3.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/minicpm3.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/yi.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/mpt.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/mobilellm.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/baichuan.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/gpt_oss.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/telechat2.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/gemma.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/gpt_bigcode.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/qwen3_next.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/longllama.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/longcat_flash.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/decilm.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/qwen3.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/deepseek_v3.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/exaone.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/moss.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/gpt_neox.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/grinmoe.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/dbrx_converted.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/codegen.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/internlm.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/granite.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/cohere.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/gpt_neo.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/qwen2.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/deepseek_v2.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/mixtral.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/base_qwen2_5_omni.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/qwen2_moe.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/hymba.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/phi.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/bloom.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/phi4.py -> build/lib/gptqmodel/models/definitions\n",
      "  copying gptqmodel/models/definitions/falcon_h1.py -> build/lib/gptqmodel/models/definitions\n",
      "  creating build/lib/gptqmodel/quantization/rotation\n",
      "  copying gptqmodel/quantization/rotation/hadamard_utils.py -> build/lib/gptqmodel/quantization/rotation\n",
      "  copying gptqmodel/quantization/rotation/__init__.py -> build/lib/gptqmodel/quantization/rotation\n",
      "  copying gptqmodel/quantization/rotation/rotation.py -> build/lib/gptqmodel/quantization/rotation\n",
      "  installing to build/bdist.macosx-11.0-arm64/wheel\n",
      "  running install\n",
      "  running install_lib\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/gptqmodel\n",
      "  copying build/lib/gptqmodel/version.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/gptqmodel/nn_modules\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/gptqmodel/nn_modules/triton_utils\n",
      "  copying build/lib/gptqmodel/nn_modules/triton_utils/mixin.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/triton_utils\n",
      "  copying build/lib/gptqmodel/nn_modules/triton_utils/custom_autotune.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/triton_utils\n",
      "  copying build/lib/gptqmodel/nn_modules/triton_utils/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/triton_utils\n",
      "  copying build/lib/gptqmodel/nn_modules/triton_utils/kernels.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/triton_utils\n",
      "  copying build/lib/gptqmodel/nn_modules/triton_utils/dequant.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/triton_utils\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/gptqmodel/nn_modules/qlinear\n",
      "  copying build/lib/gptqmodel/nn_modules/qlinear/marlin.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/qlinear\n",
      "  copying build/lib/gptqmodel/nn_modules/qlinear/bitblas.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/qlinear\n",
      "  copying build/lib/gptqmodel/nn_modules/qlinear/qqq.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/qlinear\n",
      "  copying build/lib/gptqmodel/nn_modules/qlinear/tritonv2.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/qlinear\n",
      "  copying build/lib/gptqmodel/nn_modules/qlinear/torch_fused.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/qlinear\n",
      "  copying build/lib/gptqmodel/nn_modules/qlinear/exllamav2.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/qlinear\n",
      "  copying build/lib/gptqmodel/nn_modules/qlinear/exllama_eora.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/qlinear\n",
      "  copying build/lib/gptqmodel/nn_modules/qlinear/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/qlinear\n",
      "  copying build/lib/gptqmodel/nn_modules/qlinear/utils.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/qlinear\n",
      "  copying build/lib/gptqmodel/nn_modules/qlinear/ipex.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/qlinear\n",
      "  copying build/lib/gptqmodel/nn_modules/qlinear/torch.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/qlinear\n",
      "  copying build/lib/gptqmodel/nn_modules/qlinear/exllama.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/qlinear\n",
      "  copying build/lib/gptqmodel/nn_modules/qlinear/bitblas_target_detector.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules/qlinear\n",
      "  copying build/lib/gptqmodel/nn_modules/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules\n",
      "  copying build/lib/gptqmodel/nn_modules/hooked_linear.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/nn_modules\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/gptqmodel/looper\n",
      "  copying build/lib/gptqmodel/looper/native_processor.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/looper\n",
      "  copying build/lib/gptqmodel/looper/module_looper.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/looper\n",
      "  copying build/lib/gptqmodel/looper/qqq_processor.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/looper\n",
      "  copying build/lib/gptqmodel/looper/input_cache.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/looper\n",
      "  copying build/lib/gptqmodel/looper/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/looper\n",
      "  copying build/lib/gptqmodel/looper/gptq_processor.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/looper\n",
      "  copying build/lib/gptqmodel/looper/eora_processor.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/looper\n",
      "  copying build/lib/gptqmodel/looper/named_module.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/looper\n",
      "  copying build/lib/gptqmodel/looper/dequantize_processor.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/looper\n",
      "  copying build/lib/gptqmodel/looper/loop_processor.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/looper\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/gptqmodel/eora\n",
      "  copying build/lib/gptqmodel/eora/eora.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/eora\n",
      "  copying build/lib/gptqmodel/eora/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/eora\n",
      "  copying build/lib/gptqmodel/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/rocm.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/marlin.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/bitblas.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/backend.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/vllm.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/importer.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/terminal.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/device.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/perplexity.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/mmlupro.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/logger.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/model.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/tensor.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/openai_server.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/vram.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/python.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/structure.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/eval.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/evalplus.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/torch.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/exllama.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/sglang.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/plotly.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/image.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/mlx.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/data.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/calibration.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/hf.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  copying build/lib/gptqmodel/utils/safetensor.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/utils\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/gptqmodel/models\n",
      "  copying build/lib/gptqmodel/models/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models\n",
      "  copying build/lib/gptqmodel/models/_const.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models\n",
      "  copying build/lib/gptqmodel/models/loader.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models\n",
      "  copying build/lib/gptqmodel/models/writer.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/instella.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/phi3.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/apertus.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/glm.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/dbrx.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/qwen2_vl.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/llama4.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/ovis.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/mistral.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/glm4_moe.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/olmo2.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/gpt2.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/base_qwen2_vl.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/qwen2_5_vl.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/llava_qwen2.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/chatglm.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/stablelmepoch.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/internlm2.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/mimo.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/nemotron_h.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/klear.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/gptj.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/dream.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/qwen3_moe.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/qwen2_5_omni.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/starcoder2.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/minicpm.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/ernie4_5.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/opt.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/kimi_k2.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/mllama.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/seed_oss.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/pangu_alpha.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/llama.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/gemma2.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/xverse.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/ernie4_5_moe.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/rw.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/cohere2.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/qwen.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/gemma3.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/minicpm3.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/yi.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/mpt.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/mobilellm.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/baichuan.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/gpt_oss.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/telechat2.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/gemma.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/gpt_bigcode.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/qwen3_next.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/longllama.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/longcat_flash.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/decilm.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/qwen3.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/deepseek_v3.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/exaone.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/moss.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/gpt_neox.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/grinmoe.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/dbrx_converted.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/codegen.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/internlm.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/granite.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/cohere.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/gpt_neo.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/qwen2.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/deepseek_v2.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/mixtral.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/base_qwen2_5_omni.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/qwen2_moe.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/hymba.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/phi.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/bloom.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/phi4.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/definitions/falcon_h1.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models/definitions\n",
      "  copying build/lib/gptqmodel/models/base.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models\n",
      "  copying build/lib/gptqmodel/models/auto.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/models\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/gptqmodel/adapter\n",
      "  copying build/lib/gptqmodel/adapter/remote.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/adapter\n",
      "  copying build/lib/gptqmodel/adapter/adapter.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/adapter\n",
      "  copying build/lib/gptqmodel/adapter/peft.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/adapter\n",
      "  copying build/lib/gptqmodel/adapter/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/adapter\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/gptqmodel/quantization\n",
      "  copying build/lib/gptqmodel/quantization/gar.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/quantization\n",
      "  copying build/lib/gptqmodel/quantization/qqq.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/quantization\n",
      "  copying build/lib/gptqmodel/quantization/config.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/quantization\n",
      "  copying build/lib/gptqmodel/quantization/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/quantization\n",
      "  copying build/lib/gptqmodel/quantization/quantizer.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/quantization\n",
      "  copying build/lib/gptqmodel/quantization/gptqv2.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/quantization\n",
      "  copying build/lib/gptqmodel/quantization/gptq.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/quantization\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/gptqmodel/quantization/rotation\n",
      "  copying build/lib/gptqmodel/quantization/rotation/hadamard_utils.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/quantization/rotation\n",
      "  copying build/lib/gptqmodel/quantization/rotation/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/quantization/rotation\n",
      "  copying build/lib/gptqmodel/quantization/rotation/rotation.py -> build/bdist.macosx-11.0-arm64/wheel/./gptqmodel/quantization/rotation\n",
      "  running install_egg_info\n",
      "  running egg_info\n",
      "  writing gptqmodel.egg-info/PKG-INFO\n",
      "  writing dependency_links to gptqmodel.egg-info/dependency_links.txt\n",
      "  writing requirements to gptqmodel.egg-info/requires.txt\n",
      "  writing top-level names to gptqmodel.egg-info/top_level.txt\n",
      "  reading manifest file 'gptqmodel.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  no previously-included directories found matching 'tests'\n",
      "  no previously-included directories found matching 'format'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'gptqmodel.egg-info/SOURCES.txt'\n",
      "  Copying gptqmodel.egg-info to build/bdist.macosx-11.0-arm64/wheel/./gptqmodel-4.2.5-py3.11.egg-info\n",
      "  running install_scripts\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/gptqmodel-4.2.5.dist-info/WHEEL\n",
      "  creating '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-wheel-r3l5lvrz/.tmp-m48buukr/gptqmodel-4.2.5-py3-none-any.whl' and adding 'build/bdist.macosx-11.0-arm64/wheel' to it\n",
      "  adding 'gptqmodel/__init__.py'\n",
      "  adding 'gptqmodel/version.py'\n",
      "  adding 'gptqmodel/adapter/__init__.py'\n",
      "  adding 'gptqmodel/adapter/adapter.py'\n",
      "  adding 'gptqmodel/adapter/peft.py'\n",
      "  adding 'gptqmodel/adapter/remote.py'\n",
      "  adding 'gptqmodel/eora/__init__.py'\n",
      "  adding 'gptqmodel/eora/eora.py'\n",
      "  adding 'gptqmodel/looper/__init__.py'\n",
      "  adding 'gptqmodel/looper/dequantize_processor.py'\n",
      "  adding 'gptqmodel/looper/eora_processor.py'\n",
      "  adding 'gptqmodel/looper/gptq_processor.py'\n",
      "  adding 'gptqmodel/looper/input_cache.py'\n",
      "  adding 'gptqmodel/looper/loop_processor.py'\n",
      "  adding 'gptqmodel/looper/module_looper.py'\n",
      "  adding 'gptqmodel/looper/named_module.py'\n",
      "  adding 'gptqmodel/looper/native_processor.py'\n",
      "  adding 'gptqmodel/looper/qqq_processor.py'\n",
      "  adding 'gptqmodel/models/__init__.py'\n",
      "  adding 'gptqmodel/models/_const.py'\n",
      "  adding 'gptqmodel/models/auto.py'\n",
      "  adding 'gptqmodel/models/base.py'\n",
      "  adding 'gptqmodel/models/loader.py'\n",
      "  adding 'gptqmodel/models/writer.py'\n",
      "  adding 'gptqmodel/models/definitions/__init__.py'\n",
      "  adding 'gptqmodel/models/definitions/apertus.py'\n",
      "  adding 'gptqmodel/models/definitions/baichuan.py'\n",
      "  adding 'gptqmodel/models/definitions/base_qwen2_5_omni.py'\n",
      "  adding 'gptqmodel/models/definitions/base_qwen2_vl.py'\n",
      "  adding 'gptqmodel/models/definitions/bloom.py'\n",
      "  adding 'gptqmodel/models/definitions/chatglm.py'\n",
      "  adding 'gptqmodel/models/definitions/codegen.py'\n",
      "  adding 'gptqmodel/models/definitions/cohere.py'\n",
      "  adding 'gptqmodel/models/definitions/cohere2.py'\n",
      "  adding 'gptqmodel/models/definitions/dbrx.py'\n",
      "  adding 'gptqmodel/models/definitions/dbrx_converted.py'\n",
      "  adding 'gptqmodel/models/definitions/decilm.py'\n",
      "  adding 'gptqmodel/models/definitions/deepseek_v2.py'\n",
      "  adding 'gptqmodel/models/definitions/deepseek_v3.py'\n",
      "  adding 'gptqmodel/models/definitions/dream.py'\n",
      "  adding 'gptqmodel/models/definitions/ernie4_5.py'\n",
      "  adding 'gptqmodel/models/definitions/ernie4_5_moe.py'\n",
      "  adding 'gptqmodel/models/definitions/exaone.py'\n",
      "  adding 'gptqmodel/models/definitions/falcon_h1.py'\n",
      "  adding 'gptqmodel/models/definitions/gemma.py'\n",
      "  adding 'gptqmodel/models/definitions/gemma2.py'\n",
      "  adding 'gptqmodel/models/definitions/gemma3.py'\n",
      "  adding 'gptqmodel/models/definitions/glm.py'\n",
      "  adding 'gptqmodel/models/definitions/glm4_moe.py'\n",
      "  adding 'gptqmodel/models/definitions/gpt2.py'\n",
      "  adding 'gptqmodel/models/definitions/gpt_bigcode.py'\n",
      "  adding 'gptqmodel/models/definitions/gpt_neo.py'\n",
      "  adding 'gptqmodel/models/definitions/gpt_neox.py'\n",
      "  adding 'gptqmodel/models/definitions/gpt_oss.py'\n",
      "  adding 'gptqmodel/models/definitions/gptj.py'\n",
      "  adding 'gptqmodel/models/definitions/granite.py'\n",
      "  adding 'gptqmodel/models/definitions/grinmoe.py'\n",
      "  adding 'gptqmodel/models/definitions/hymba.py'\n",
      "  adding 'gptqmodel/models/definitions/instella.py'\n",
      "  adding 'gptqmodel/models/definitions/internlm.py'\n",
      "  adding 'gptqmodel/models/definitions/internlm2.py'\n",
      "  adding 'gptqmodel/models/definitions/kimi_k2.py'\n",
      "  adding 'gptqmodel/models/definitions/klear.py'\n",
      "  adding 'gptqmodel/models/definitions/llama.py'\n",
      "  adding 'gptqmodel/models/definitions/llama4.py'\n",
      "  adding 'gptqmodel/models/definitions/llava_qwen2.py'\n",
      "  adding 'gptqmodel/models/definitions/longcat_flash.py'\n",
      "  adding 'gptqmodel/models/definitions/longllama.py'\n",
      "  adding 'gptqmodel/models/definitions/mimo.py'\n",
      "  adding 'gptqmodel/models/definitions/minicpm.py'\n",
      "  adding 'gptqmodel/models/definitions/minicpm3.py'\n",
      "  adding 'gptqmodel/models/definitions/mistral.py'\n",
      "  adding 'gptqmodel/models/definitions/mixtral.py'\n",
      "  adding 'gptqmodel/models/definitions/mllama.py'\n",
      "  adding 'gptqmodel/models/definitions/mobilellm.py'\n",
      "  adding 'gptqmodel/models/definitions/moss.py'\n",
      "  adding 'gptqmodel/models/definitions/mpt.py'\n",
      "  adding 'gptqmodel/models/definitions/nemotron_h.py'\n",
      "  adding 'gptqmodel/models/definitions/olmo2.py'\n",
      "  adding 'gptqmodel/models/definitions/opt.py'\n",
      "  adding 'gptqmodel/models/definitions/ovis.py'\n",
      "  adding 'gptqmodel/models/definitions/pangu_alpha.py'\n",
      "  adding 'gptqmodel/models/definitions/phi.py'\n",
      "  adding 'gptqmodel/models/definitions/phi3.py'\n",
      "  adding 'gptqmodel/models/definitions/phi4.py'\n",
      "  adding 'gptqmodel/models/definitions/qwen.py'\n",
      "  adding 'gptqmodel/models/definitions/qwen2.py'\n",
      "  adding 'gptqmodel/models/definitions/qwen2_5_omni.py'\n",
      "  adding 'gptqmodel/models/definitions/qwen2_5_vl.py'\n",
      "  adding 'gptqmodel/models/definitions/qwen2_moe.py'\n",
      "  adding 'gptqmodel/models/definitions/qwen2_vl.py'\n",
      "  adding 'gptqmodel/models/definitions/qwen3.py'\n",
      "  adding 'gptqmodel/models/definitions/qwen3_moe.py'\n",
      "  adding 'gptqmodel/models/definitions/qwen3_next.py'\n",
      "  adding 'gptqmodel/models/definitions/rw.py'\n",
      "  adding 'gptqmodel/models/definitions/seed_oss.py'\n",
      "  adding 'gptqmodel/models/definitions/stablelmepoch.py'\n",
      "  adding 'gptqmodel/models/definitions/starcoder2.py'\n",
      "  adding 'gptqmodel/models/definitions/telechat2.py'\n",
      "  adding 'gptqmodel/models/definitions/xverse.py'\n",
      "  adding 'gptqmodel/models/definitions/yi.py'\n",
      "  adding 'gptqmodel/nn_modules/__init__.py'\n",
      "  adding 'gptqmodel/nn_modules/hooked_linear.py'\n",
      "  adding 'gptqmodel/nn_modules/qlinear/__init__.py'\n",
      "  adding 'gptqmodel/nn_modules/qlinear/bitblas.py'\n",
      "  adding 'gptqmodel/nn_modules/qlinear/bitblas_target_detector.py'\n",
      "  adding 'gptqmodel/nn_modules/qlinear/exllama.py'\n",
      "  adding 'gptqmodel/nn_modules/qlinear/exllama_eora.py'\n",
      "  adding 'gptqmodel/nn_modules/qlinear/exllamav2.py'\n",
      "  adding 'gptqmodel/nn_modules/qlinear/ipex.py'\n",
      "  adding 'gptqmodel/nn_modules/qlinear/marlin.py'\n",
      "  adding 'gptqmodel/nn_modules/qlinear/qqq.py'\n",
      "  adding 'gptqmodel/nn_modules/qlinear/torch.py'\n",
      "  adding 'gptqmodel/nn_modules/qlinear/torch_fused.py'\n",
      "  adding 'gptqmodel/nn_modules/qlinear/tritonv2.py'\n",
      "  adding 'gptqmodel/nn_modules/qlinear/utils.py'\n",
      "  adding 'gptqmodel/nn_modules/triton_utils/__init__.py'\n",
      "  adding 'gptqmodel/nn_modules/triton_utils/custom_autotune.py'\n",
      "  adding 'gptqmodel/nn_modules/triton_utils/dequant.py'\n",
      "  adding 'gptqmodel/nn_modules/triton_utils/kernels.py'\n",
      "  adding 'gptqmodel/nn_modules/triton_utils/mixin.py'\n",
      "  adding 'gptqmodel/quantization/__init__.py'\n",
      "  adding 'gptqmodel/quantization/config.py'\n",
      "  adding 'gptqmodel/quantization/gar.py'\n",
      "  adding 'gptqmodel/quantization/gptq.py'\n",
      "  adding 'gptqmodel/quantization/gptqv2.py'\n",
      "  adding 'gptqmodel/quantization/qqq.py'\n",
      "  adding 'gptqmodel/quantization/quantizer.py'\n",
      "  adding 'gptqmodel/quantization/rotation/__init__.py'\n",
      "  adding 'gptqmodel/quantization/rotation/hadamard_utils.py'\n",
      "  adding 'gptqmodel/quantization/rotation/rotation.py'\n",
      "  adding 'gptqmodel/utils/__init__.py'\n",
      "  adding 'gptqmodel/utils/backend.py'\n",
      "  adding 'gptqmodel/utils/bitblas.py'\n",
      "  adding 'gptqmodel/utils/calibration.py'\n",
      "  adding 'gptqmodel/utils/data.py'\n",
      "  adding 'gptqmodel/utils/device.py'\n",
      "  adding 'gptqmodel/utils/eval.py'\n",
      "  adding 'gptqmodel/utils/evalplus.py'\n",
      "  adding 'gptqmodel/utils/exllama.py'\n",
      "  adding 'gptqmodel/utils/hf.py'\n",
      "  adding 'gptqmodel/utils/image.py'\n",
      "  adding 'gptqmodel/utils/importer.py'\n",
      "  adding 'gptqmodel/utils/logger.py'\n",
      "  adding 'gptqmodel/utils/marlin.py'\n",
      "  adding 'gptqmodel/utils/mlx.py'\n",
      "  adding 'gptqmodel/utils/mmlupro.py'\n",
      "  adding 'gptqmodel/utils/model.py'\n",
      "  adding 'gptqmodel/utils/openai_server.py'\n",
      "  adding 'gptqmodel/utils/perplexity.py'\n",
      "  adding 'gptqmodel/utils/plotly.py'\n",
      "  adding 'gptqmodel/utils/python.py'\n",
      "  adding 'gptqmodel/utils/rocm.py'\n",
      "  adding 'gptqmodel/utils/safetensor.py'\n",
      "  adding 'gptqmodel/utils/sglang.py'\n",
      "  adding 'gptqmodel/utils/structure.py'\n",
      "  adding 'gptqmodel/utils/tensor.py'\n",
      "  adding 'gptqmodel/utils/terminal.py'\n",
      "  adding 'gptqmodel/utils/torch.py'\n",
      "  adding 'gptqmodel/utils/vllm.py'\n",
      "  adding 'gptqmodel/utils/vram.py'\n",
      "  adding 'gptqmodel-4.2.5.dist-info/licenses/LICENSE'\n",
      "  adding 'gptqmodel-4.2.5.dist-info/METADATA'\n",
      "  adding 'gptqmodel-4.2.5.dist-info/WHEEL'\n",
      "  adding 'gptqmodel-4.2.5.dist-info/top_level.txt'\n",
      "  adding 'gptqmodel-4.2.5.dist-info/RECORD'\n",
      "  removing build/bdist.macosx-11.0-arm64/wheel\n",
      "\u001b[?25hdone\n",
      "  Created wheel for gptqmodel: filename=gptqmodel-4.2.5-py3-none-any.whl size=335115 sha256=a61a54f3b10953ac8c39625c4e3754a4e4556c40f9ae88d8abc9e60df0d11e30\n",
      "  Stored in directory: /Users/atharvabot7/Library/Caches/pip/wheels/81/1d/00/6fe5be5711e381c042580e362ba76a931e594250231f6bd8c8\n",
      "\u001b[33m  DEPRECATION: Building 'device-smi' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'device-smi'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for device-smi (setup.py) ... \u001b[?25l  Running command python setup.py bdist_wheel\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/_distutils/dist.py:289: UserWarning: Unknown distribution option: 'platform'\n",
      "    warnings.warn(msg)\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  !!\n",
      "\n",
      "          ********************************************************************************\n",
      "          Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "\n",
      "          License :: OSI Approved :: Apache Software License\n",
      "\n",
      "          See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "          ********************************************************************************\n",
      "\n",
      "  !!\n",
      "    self._finalize_license_expression()\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build/lib/device_smi\n",
      "  copying device_smi/intel.py -> build/lib/device_smi\n",
      "  copying device_smi/nvidia.py -> build/lib/device_smi\n",
      "  copying device_smi/device.py -> build/lib/device_smi\n",
      "  copying device_smi/cpu.py -> build/lib/device_smi\n",
      "  copying device_smi/os.py -> build/lib/device_smi\n",
      "  copying device_smi/__init__.py -> build/lib/device_smi\n",
      "  copying device_smi/apple.py -> build/lib/device_smi\n",
      "  copying device_smi/base.py -> build/lib/device_smi\n",
      "  copying device_smi/amd.py -> build/lib/device_smi\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "  !!\n",
      "\n",
      "          ********************************************************************************\n",
      "          Please avoid running ``setup.py`` directly.\n",
      "          Instead, use pypa/build, pypa/installer or other\n",
      "          standards-based tools.\n",
      "\n",
      "          By 2025-Oct-31, you need to update your project and remove deprecated calls\n",
      "          or your builds will no longer be supported.\n",
      "\n",
      "          See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "          ********************************************************************************\n",
      "\n",
      "  !!\n",
      "    self.initialize_options()\n",
      "  installing to build/bdist.macosx-11.0-arm64/wheel\n",
      "  running install\n",
      "  running install_lib\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/device_smi\n",
      "  copying build/lib/device_smi/intel.py -> build/bdist.macosx-11.0-arm64/wheel/./device_smi\n",
      "  copying build/lib/device_smi/nvidia.py -> build/bdist.macosx-11.0-arm64/wheel/./device_smi\n",
      "  copying build/lib/device_smi/device.py -> build/bdist.macosx-11.0-arm64/wheel/./device_smi\n",
      "  copying build/lib/device_smi/cpu.py -> build/bdist.macosx-11.0-arm64/wheel/./device_smi\n",
      "  copying build/lib/device_smi/os.py -> build/bdist.macosx-11.0-arm64/wheel/./device_smi\n",
      "  copying build/lib/device_smi/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./device_smi\n",
      "  copying build/lib/device_smi/apple.py -> build/bdist.macosx-11.0-arm64/wheel/./device_smi\n",
      "  copying build/lib/device_smi/base.py -> build/bdist.macosx-11.0-arm64/wheel/./device_smi\n",
      "  copying build/lib/device_smi/amd.py -> build/bdist.macosx-11.0-arm64/wheel/./device_smi\n",
      "  running install_egg_info\n",
      "  running egg_info\n",
      "  writing device_smi.egg-info/PKG-INFO\n",
      "  writing dependency_links to device_smi.egg-info/dependency_links.txt\n",
      "  writing top-level names to device_smi.egg-info/top_level.txt\n",
      "  reading manifest file 'device_smi.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'device_smi.egg-info/SOURCES.txt'\n",
      "  Copying device_smi.egg-info to build/bdist.macosx-11.0-arm64/wheel/./device_smi-0.4.1-py3.11.egg-info\n",
      "  running install_scripts\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/device_smi-0.4.1.dist-info/WHEEL\n",
      "  creating '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-wheel-ql1416t1/device_smi-0.4.1-py3-none-any.whl' and adding 'build/bdist.macosx-11.0-arm64/wheel' to it\n",
      "  adding 'device_smi/__init__.py'\n",
      "  adding 'device_smi/amd.py'\n",
      "  adding 'device_smi/apple.py'\n",
      "  adding 'device_smi/base.py'\n",
      "  adding 'device_smi/cpu.py'\n",
      "  adding 'device_smi/device.py'\n",
      "  adding 'device_smi/intel.py'\n",
      "  adding 'device_smi/nvidia.py'\n",
      "  adding 'device_smi/os.py'\n",
      "  adding 'device_smi-0.4.1.dist-info/licenses/LICENSE'\n",
      "  adding 'device_smi-0.4.1.dist-info/METADATA'\n",
      "  adding 'device_smi-0.4.1.dist-info/WHEEL'\n",
      "  adding 'device_smi-0.4.1.dist-info/top_level.txt'\n",
      "  adding 'device_smi-0.4.1.dist-info/RECORD'\n",
      "  removing build/bdist.macosx-11.0-arm64/wheel\n",
      "\u001b[?25hdone\n",
      "  Created wheel for device-smi: filename=device_smi-0.4.1-py3-none-any.whl size=17972 sha256=1120a08190ffcce6c83399ad371129f686c19c20142cb5954422d3af5adc5a7e\n",
      "  Stored in directory: /Users/atharvabot7/Library/Caches/pip/wheels/83/82/37/d8751fd90fc238023fe6d5e3c7d7deedb07f03a3ed7264aca2\n",
      "\u001b[33m  DEPRECATION: Building 'logbar' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'logbar'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for logbar (setup.py) ... \u001b[?25l  Running command python setup.py bdist_wheel\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/_distutils/dist.py:289: UserWarning: Unknown distribution option: 'platform'\n",
      "    warnings.warn(msg)\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  !!\n",
      "\n",
      "          ********************************************************************************\n",
      "          Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "\n",
      "          License :: OSI Approved :: Apache Software License\n",
      "\n",
      "          See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "          ********************************************************************************\n",
      "\n",
      "  !!\n",
      "    self._finalize_license_expression()\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build/lib/logbar\n",
      "  copying logbar/terminal.py -> build/lib/logbar\n",
      "  copying logbar/util.py -> build/lib/logbar\n",
      "  copying logbar/__init__.py -> build/lib/logbar\n",
      "  copying logbar/progress.py -> build/lib/logbar\n",
      "  copying logbar/logbar.py -> build/lib/logbar\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "  !!\n",
      "\n",
      "          ********************************************************************************\n",
      "          Please avoid running ``setup.py`` directly.\n",
      "          Instead, use pypa/build, pypa/installer or other\n",
      "          standards-based tools.\n",
      "\n",
      "          By 2025-Oct-31, you need to update your project and remove deprecated calls\n",
      "          or your builds will no longer be supported.\n",
      "\n",
      "          See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "          ********************************************************************************\n",
      "\n",
      "  !!\n",
      "    self.initialize_options()\n",
      "  installing to build/bdist.macosx-11.0-arm64/wheel\n",
      "  running install\n",
      "  running install_lib\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/logbar\n",
      "  copying build/lib/logbar/terminal.py -> build/bdist.macosx-11.0-arm64/wheel/./logbar\n",
      "  copying build/lib/logbar/util.py -> build/bdist.macosx-11.0-arm64/wheel/./logbar\n",
      "  copying build/lib/logbar/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./logbar\n",
      "  copying build/lib/logbar/progress.py -> build/bdist.macosx-11.0-arm64/wheel/./logbar\n",
      "  copying build/lib/logbar/logbar.py -> build/bdist.macosx-11.0-arm64/wheel/./logbar\n",
      "  running install_egg_info\n",
      "  running egg_info\n",
      "  writing logbar.egg-info/PKG-INFO\n",
      "  writing dependency_links to logbar.egg-info/dependency_links.txt\n",
      "  writing top-level names to logbar.egg-info/top_level.txt\n",
      "  reading manifest file 'logbar.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  no previously-included directories found matching 'tests'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'logbar.egg-info/SOURCES.txt'\n",
      "  Copying logbar.egg-info to build/bdist.macosx-11.0-arm64/wheel/./logbar-0.0.4-py3.11.egg-info\n",
      "  running install_scripts\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/logbar-0.0.4.dist-info/WHEEL\n",
      "  creating '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-wheel-gkxvtdtf/logbar-0.0.4-py3-none-any.whl' and adding 'build/bdist.macosx-11.0-arm64/wheel' to it\n",
      "  adding 'logbar/__init__.py'\n",
      "  adding 'logbar/logbar.py'\n",
      "  adding 'logbar/progress.py'\n",
      "  adding 'logbar/terminal.py'\n",
      "  adding 'logbar/util.py'\n",
      "  adding 'logbar-0.0.4.dist-info/licenses/LICENSE'\n",
      "  adding 'logbar-0.0.4.dist-info/METADATA'\n",
      "  adding 'logbar-0.0.4.dist-info/WHEEL'\n",
      "  adding 'logbar-0.0.4.dist-info/top_level.txt'\n",
      "  adding 'logbar-0.0.4.dist-info/RECORD'\n",
      "  removing build/bdist.macosx-11.0-arm64/wheel\n",
      "\u001b[?25hdone\n",
      "  Created wheel for logbar: filename=logbar-0.0.4-py3-none-any.whl size=12715 sha256=d39640ca79cfba868b382e9970472e5a8f38bb86b16f8d09da05827220428a02\n",
      "  Stored in directory: /Users/atharvabot7/Library/Caches/pip/wheels/65/0a/fc/2ee56584257132c0ea647e287239b349775e3fcc31c28b9d6c\n",
      "\u001b[33m  DEPRECATION: Building 'tokenicer' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'tokenicer'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for tokenicer (setup.py) ... \u001b[?25l  Running command python setup.py bdist_wheel\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/_distutils/dist.py:289: UserWarning: Unknown distribution option: 'platform'\n",
      "    warnings.warn(msg)\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  !!\n",
      "\n",
      "          ********************************************************************************\n",
      "          Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "\n",
      "          License :: OSI Approved :: Apache Software License\n",
      "\n",
      "          See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "          ********************************************************************************\n",
      "\n",
      "  !!\n",
      "    self._finalize_license_expression()\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build/lib/tokenicer\n",
      "  copying tokenicer/util.py -> build/lib/tokenicer\n",
      "  copying tokenicer/__init__.py -> build/lib/tokenicer\n",
      "  copying tokenicer/tokenicer.py -> build/lib/tokenicer\n",
      "  copying tokenicer/const.py -> build/lib/tokenicer\n",
      "  /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "  !!\n",
      "\n",
      "          ********************************************************************************\n",
      "          Please avoid running ``setup.py`` directly.\n",
      "          Instead, use pypa/build, pypa/installer or other\n",
      "          standards-based tools.\n",
      "\n",
      "          By 2025-Oct-31, you need to update your project and remove deprecated calls\n",
      "          or your builds will no longer be supported.\n",
      "\n",
      "          See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "          ********************************************************************************\n",
      "\n",
      "  !!\n",
      "    self.initialize_options()\n",
      "  installing to build/bdist.macosx-11.0-arm64/wheel\n",
      "  running install\n",
      "  running install_lib\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/tokenicer\n",
      "  copying build/lib/tokenicer/util.py -> build/bdist.macosx-11.0-arm64/wheel/./tokenicer\n",
      "  copying build/lib/tokenicer/__init__.py -> build/bdist.macosx-11.0-arm64/wheel/./tokenicer\n",
      "  copying build/lib/tokenicer/tokenicer.py -> build/bdist.macosx-11.0-arm64/wheel/./tokenicer\n",
      "  copying build/lib/tokenicer/const.py -> build/bdist.macosx-11.0-arm64/wheel/./tokenicer\n",
      "  running install_egg_info\n",
      "  running egg_info\n",
      "  writing tokenicer.egg-info/PKG-INFO\n",
      "  writing dependency_links to tokenicer.egg-info/dependency_links.txt\n",
      "  writing requirements to tokenicer.egg-info/requires.txt\n",
      "  writing top-level names to tokenicer.egg-info/top_level.txt\n",
      "  reading manifest file 'tokenicer.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  no previously-included directories found matching 'tests'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'tokenicer.egg-info/SOURCES.txt'\n",
      "  Copying tokenicer.egg-info to build/bdist.macosx-11.0-arm64/wheel/./tokenicer-0.0.5-py3.11.egg-info\n",
      "  running install_scripts\n",
      "  creating build/bdist.macosx-11.0-arm64/wheel/tokenicer-0.0.5.dist-info/WHEEL\n",
      "  creating '/private/var/folders/p_/v95prvpj4cz7y53gvmgm1d_r0000gn/T/pip-wheel-rdsdsht7/tokenicer-0.0.5-py3-none-any.whl' and adding 'build/bdist.macosx-11.0-arm64/wheel' to it\n",
      "  adding 'tokenicer/__init__.py'\n",
      "  adding 'tokenicer/const.py'\n",
      "  adding 'tokenicer/tokenicer.py'\n",
      "  adding 'tokenicer/util.py'\n",
      "  adding 'tokenicer-0.0.5.dist-info/licenses/LICENSE'\n",
      "  adding 'tokenicer-0.0.5.dist-info/METADATA'\n",
      "  adding 'tokenicer-0.0.5.dist-info/WHEEL'\n",
      "  adding 'tokenicer-0.0.5.dist-info/top_level.txt'\n",
      "  adding 'tokenicer-0.0.5.dist-info/RECORD'\n",
      "  removing build/bdist.macosx-11.0-arm64/wheel\n",
      "\u001b[?25hdone\n",
      "  Created wheel for tokenicer: filename=tokenicer-0.0.5-py3-none-any.whl size=11634 sha256=37a700c4e60cd8c27c3ba6ce7f8e9e1db71c2995ac9f635107b0ebc760aaebbd\n",
      "  Stored in directory: /Users/atharvabot7/Library/Caches/pip/wheels/1e/3d/b0/0924a859a3cba78030b38e85a3444cecee744922b8f552a073\n",
      "Successfully built gptqmodel device-smi logbar tokenicer\n",
      "Installing collected packages: pycodestyle, protobuf, pluggy, pillow, maturin, logbar, iniconfig, hf_transfer, device-smi, pytest, autopep8, random_word, accelerate, tokenicer, gptqmodel\n",
      "\u001b[2K  changing mode of /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/bin/pycodestyle to 755\n",
      "\u001b[2K  changing mode of /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/bin/py.test to 7550m [pytest]\n",
      "\u001b[2K  changing mode of /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/bin/pytest to 755[pytest]\n",
      "\u001b[2K  changing mode of /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/bin/autopep8 to 755ytest]\n",
      "\u001b[2K  Attempting uninstall: accelerate━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [pytest]\n",
      "\u001b[2K    Found existing installation: accelerate 0.30.15;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [pytest]\n",
      "\u001b[2K    Uninstalling accelerate-0.30.1:━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [pytest]\n",
      "\u001b[2K      Removing file or directory /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/bin/accelerate\n",
      "\u001b[2K      Removing file or directory /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/bin/accelerate-config\n",
      "\u001b[2K      Removing file or directory /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/bin/accelerate-estimate-memory\n",
      "\u001b[2K      Removing file or directory /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/bin/accelerate-launch\n",
      "\u001b[2K      Removing file or directory /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/accelerate-0.30.1.dist-info/\n",
      "\u001b[2K      Removing file or directory /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/accelerate/\n",
      "\u001b[2K      Successfully uninstalled accelerate-0.30.18;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [pytest]\n",
      "\u001b[2K  changing mode of /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/bin/accelerate to 755[accelerate]\n",
      "\u001b[2K  changing mode of /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/bin/accelerate-config to 755]\n",
      "\u001b[2K  changing mode of /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/bin/accelerate-estimate-memory to 755\n",
      "\u001b[2K  changing mode of /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/bin/accelerate-launch to 755]\n",
      "\u001b[2K  changing mode of /Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/bin/accelerate-merge-weights to 755\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [gptqmodel][0m \u001b[32m14/15\u001b[0m [gptqmodel]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.11.0 autopep8-2.3.2 device-smi-0.4.1 gptqmodel-4.2.5 hf_transfer-0.1.9 iniconfig-2.3.0 logbar-0.0.4 maturin-1.9.6 pillow-12.0.0 pluggy-1.6.0 protobuf-6.33.0 pycodestyle-2.14.0 pytest-8.4.2 random_word-1.0.13 tokenicer-0.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install -v gptqmodel --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0394c3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf>=6.32.0\n",
      "  Using cached protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Using cached protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.5\n",
      "    Uninstalling protobuf-5.29.5:\n",
      "      Successfully uninstalled protobuf-5.29.5\n",
      "Successfully installed protobuf-6.33.0\n"
     ]
    }
   ],
   "source": [
    "!pip install \"protobuf>=6.32.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b45f660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33mWARN\u001b[0m  Python GIL is enabled: Multi-gpu quant acceleration for MoE models is sub-optimal and multi-core accelerated cpu packing is also disabled. We recommend Python >= 3.13.3t with Pytorch > 2.8 for mult-gpu quantization and multi-cpu packing with env `PYTHON_GIL=0`.\n",
      "\u001b[33mWARN\u001b[0m  Feature `utils/Perplexity` requires python GIL or Python >= 3.13.3T (T for Threading-Free edition of Python) plus Torch 2.8. Feature is currently skipped/disabled.\n",
      "\u001b[32mINFO\u001b[0m  ENV: Auto setting PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True' for memory saving.\n",
      "\u001b[32mINFO\u001b[0m  ENV: Auto setting CUDA_DEVICE_ORDER=PCI_BUS_ID for correctness.          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvabot7/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/Context.cpp:85.)\n",
      "  self.setter(val)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BACKEND',\n",
       " 'BaseQuantizeConfig',\n",
       " 'GPTQModel',\n",
       " 'QuantizeConfig',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'adapter',\n",
       " 'exllama_set_max_input_length',\n",
       " 'get_best_device',\n",
       " 'looper',\n",
       " 'models',\n",
       " 'nn_modules',\n",
       " 'os',\n",
       " 'quantization',\n",
       " 'utils',\n",
       " 'version']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gptqmodel\n",
    "dir(gptqmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e33b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gptqmodel import GPTQModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d2a8eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from_quantized: adapter: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 8 files: 100%|██████████| 8/8 [00:43<00:00,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m  Loader: Auto dtype (MPS or XPU): `torch.float16`                         \n",
      "\u001b[32mINFO\u001b[0m  Estimated Quantization BPW (bits per weight): 4.85 bpw, based on [bits: 4, group_size: 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m   Kernel: Auto-selection: adding candidate `TorchQuantLinear`             \n",
      "\u001b[32mINFO\u001b[0m  Kernel: candidates -> `[TorchQuantLinear]`                               \n",
      "\u001b[32mINFO\u001b[0m  Kernel: selected -> `TorchQuantLinear`.                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.modeling:The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m  Format: Converting `checkpoint_format` from `FORMAT.GPTQ` to internal `FORMAT.GPTQ_V2`.\n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Conversion complete: 0.046690940856933594s                       \n",
      "\u001b[32mINFO\u001b[0m   Kernel: Auto-selection: adding candidate `TorchQuantLinear`             \n",
      "\u001b[32mINFO\u001b[0m  Optimize: `TorchQuantLinear` compilation triggered.                      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tokenicer.tokenicer:Tokenicer: Auto fixed pad_token_id=128004 (token='<|finetune_right_pad_id|>').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m  Model: Loaded `generation_config`: GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n",
      "\u001b[32mINFO\u001b[0m  Model: `generation_config.json` not found. Skipped checking.             \n",
      "\u001b[32mINFO\u001b[0m  Kernel: loaded -> `[TorchQuantLinear]`                                   \n"
     ]
    }
   ],
   "source": [
    "model = GPTQModel.load(\"ModelCloud/Llama-3.2-1B-Instruct-gptqmodel-4bit-vortex-v2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d212eb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaGPTQ(\n",
       "  (model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(128256, 2048)\n",
       "      (layers): ModuleList(\n",
       "        (0-15): 16 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaAttention(\n",
       "            (q_proj): TorchQuantLinear()\n",
       "            (k_proj): TorchQuantLinear()\n",
       "            (v_proj): TorchQuantLinear()\n",
       "            (o_proj): TorchQuantLinear()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): TorchQuantLinear()\n",
       "            (up_proj): TorchQuantLinear()\n",
       "            (down_proj): TorchQuantLinear()\n",
       "            (act_fn): SiLUActivation()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd8869a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.generate(\"Explain the theory of relativity in simple terms.\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "857e119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Explain the theory of relativity in simple terms. Albert Einstein's theory of relativity revolutionized our understanding of space and time.\n",
      "\n",
      "## Step 1\n"
     ]
    }
   ],
   "source": [
    "print(model.tokenizer.decode(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46d5e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "244c24da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9187b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_path = \"Llama-3.2-1B-Instruct-gptqmodel-4bit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bcaf213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 356318 examples [00:03, 116624.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "calibration_dataset = load_dataset(\n",
    "    \"allenai/c4\",\n",
    "    data_files = \"en/c4-train.00001-of-01024.json.gz\",\n",
    "    split=\"train\",\n",
    ").select(range(1024))[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cb97981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gptqmodel import GPTQModel, QuantizeConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66a357bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = QuantizeConfig(\n",
    "    bits=4,\n",
    "    group_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edaba1cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct.\n403 Client Error. (Request ID: Root=1-68facaf9-75360d040014bd8b7a590f67;9696c7de-d8b5-442f-a43b-2b6b2a57f4ac)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct to ask for access.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:402\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mGatedRepoError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/transformers/utils/hub.py:479\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    478\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/huggingface_hub/file_download.py:1007\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/huggingface_hub/file_download.py:1114\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1113\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1114\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/huggingface_hub/file_download.py:1655\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1650\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1651\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1652\u001b[39m ):\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1655\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1657\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/huggingface_hub/file_download.py:1543\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1542\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1543\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/huggingface_hub/file_download.py:1460\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1459\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1460\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1462\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1469\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/huggingface_hub/file_download.py:283\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    291\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/huggingface_hub/file_download.py:307\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    306\u001b[39m response = http_backoff(method=method, url=url, **params)\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:419\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    416\u001b[39m     message = (\n\u001b[32m    417\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    418\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_message == \u001b[33m\"\u001b[39m\u001b[33mAccess to this resource is disabled.\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mGatedRepoError\u001b[39m: 403 Client Error. (Request ID: Root=1-68facaf9-75360d040014bd8b7a590f67;9696c7de-d8b5-442f-a43b-2b6b2a57f4ac)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct to ask for access.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mGPTQModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/gptqmodel/models/auto.py:275\u001b[39m, in \u001b[36mGPTQModel.load\u001b[39m\u001b[34m(cls, model_id_or_path, quantize_config, device_map, device, backend, trust_remote_code, verify_hash, debug, **kwargs)\u001b[39m\n\u001b[32m    272\u001b[39m     backend = BACKEND(backend)\n\u001b[32m    274\u001b[39m is_quantized = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    276\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mquantization_config\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    277\u001b[39m     is_quantized = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:1332\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m trust_remote_code = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtrust_remote_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1330\u001b[39m code_revision = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1332\u001b[39m config_dict, unused_kwargs = \u001b[43mPretrainedConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1333\u001b[39m has_remote_code = \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1334\u001b[39m has_local_code = \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/transformers/configuration_utils.py:662\u001b[39m, in \u001b[36mPretrainedConfig.get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    660\u001b[39m original_kwargs = copy.deepcopy(kwargs)\n\u001b[32m    661\u001b[39m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m config_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    664\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/transformers/configuration_utils.py:721\u001b[39m, in \u001b[36mPretrainedConfig._get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    717\u001b[39m configuration_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_configuration_file\u001b[39m\u001b[33m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    720\u001b[39m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m721\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/transformers/utils/hub.py:322\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    265\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    266\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    267\u001b[39m     **kwargs,\n\u001b[32m    268\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    269\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    271\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/MLOPS-Tutorials/Fine-Tuning-Practice/gptq/lib/python3.11/site-packages/transformers/utils/hub.py:543\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    541\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[32m    542\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    544\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMake sure to have access to it at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    545\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    546\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, LocalEntryNotFoundError):\n\u001b[32m    548\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n",
      "\u001b[31mOSError\u001b[39m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct.\n403 Client Error. (Request ID: Root=1-68facaf9-75360d040014bd8b7a590f67;9696c7de-d8b5-442f-a43b-2b6b2a57f4ac)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct to ask for access."
     ]
    }
   ],
   "source": [
    "model = GPTQModel.load(model_id,quant_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c698a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.quantize(calibration_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(quant_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f97f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180754d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
