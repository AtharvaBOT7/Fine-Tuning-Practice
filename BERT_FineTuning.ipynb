{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caab323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting numpy>=1.17 (from datasets)\n",
      "  Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-21.0.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.9.0,>=2023.1.0 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.35.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in ./finetuning/lib/python3.10/site-packages (from datasets) (25.0)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.12.15-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.7.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.6.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.20.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in ./finetuning/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (4.15.0)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.24.0->datasets)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets)\n",
      "  Using cached charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./finetuning/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./finetuning/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached aiohttp-3.12.15-cp310-cp310-macosx_11_0_arm64.whl (468 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached multidict-6.6.4-cp310-cp310-macosx_11_0_arm64.whl (44 kB)\n",
      "Using cached yarl-1.20.1-cp310-cp310-macosx_11_0_arm64.whl (89 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.7.0-cp310-cp310-macosx_11_0_arm64.whl (46 kB)\n",
      "Downloading huggingface_hub-0.35.0-py3-none-any.whl (563 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.4/563.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
      "Using cached propcache-0.3.2-cp310-cp310-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached pyarrow-21.0.0-cp310-cp310-macosx_12_0_arm64.whl (31.2 MB)\n",
      "Using cached PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl (207 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached pandas-2.3.2-cp310-cp310-macosx_11_0_arm64.whl (10.8 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached xxhash-3.5.0-cp310-cp310-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: pytz, xxhash, urllib3, tzdata, tqdm, pyyaml, pyarrow, propcache, numpy, multidict, idna, hf-xet, fsspec, frozenlist, filelock, dill, charset_normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, requests, pandas, multiprocess, aiosignal, huggingface-hub, aiohttp, datasets\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/29\u001b[0m [datasets]5;237m━\u001b[0m \u001b[32m28/29\u001b[0m [datasets]ce-hub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 async-timeout-5.0.1 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 datasets-4.1.1 dill-0.4.0 filelock-3.19.1 frozenlist-1.7.0 fsspec-2025.9.0 hf-xet-1.1.10 huggingface-hub-0.35.0 idna-3.10 multidict-6.6.4 multiprocess-0.70.16 numpy-2.2.6 pandas-2.3.2 propcache-0.3.2 pyarrow-21.0.0 pytz-2025.2 pyyaml-6.0.2 requests-2.32.5 tqdm-4.67.1 tzdata-2025.2 urllib3-2.5.0 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd22e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from transformers import TrainingArguments, Trainer, BertForSequenceClassification\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a811b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 16000/16000 [00:00<00:00, 1196897.82 examples/s]\n",
      "Generating validation split: 100%|██████████| 2000/2000 [00:00<00:00, 630674.99 examples/s]\n",
      "Generating test split: 100%|██████████| 2000/2000 [00:00<00:00, 940426.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "dataset = load_dataset(\"emotion\", split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91a3b138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 16000/16000 [00:00<00:00, 487076.14 examples/s]\n",
      "Map: 100%|██████████| 12187/12187 [00:00<00:00, 49015.85 examples/s]\n",
      "Casting the dataset: 100%|██████████| 12187/12187 [00:00<00:00, 4905564.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sadness', 'joy', 'anger']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda x: x['label'] in [0,1,3])\n",
    "\n",
    "label_map = {0:0, 1:1, 3:2}\n",
    "dataset = dataset.map(lambda x: {\"label\": label_map[x[\"label\"]]})\n",
    "\n",
    "new_label_feature = ClassLabel(num_classes = 3, names = [\"sadness\", \"joy\", \"anger\"])\n",
    "dataset = dataset.cast_column(\"label\", new_label_feature)\n",
    "\n",
    "print(dataset.features[\"label\"].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c11b6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a033d48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 9749\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2438\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "265d27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = dataset['train']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d8697d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column(['im so relieved and feel so much more like myself now that this is resolved this being almost nothing at all actually just some weird energy and i cant wait to be back at camp even though ill be hacking and coughing and spluttering all day long', 'im feeling lucky button after that you will go to the landing page where you will found the alternative google search engine homepage with colors theme depend on the keywords below', 'i just am so tired of feeling lonely and yet when someone comes along who can take away that feeling i run away', 'i like about this song is how it feels bouncy and matches tiggers bouncy personality', 'i feel so repressed when compared to dear a href http eurodancemix'])\n"
     ]
    }
   ],
   "source": [
    "print(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8af3f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9749\n"
     ]
    }
   ],
   "source": [
    "print(len(train_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87fd47dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = dataset['train']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8503258f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column([1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19c991eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9749\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c576dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_texts = dataset['test']['text']\n",
    "val_labels = dataset['test']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87c9f90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2438\n",
      "2438\n"
     ]
    }
   ],
   "source": [
    "print(len(val_texts))\n",
    "print(len(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78b0b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4be8dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding = True, truncation = True, return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb19359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9749/9749 [00:02<00:00, 4254.16 examples/s]\n",
      "Map: 100%|██████████| 2438/2438 [00:00<00:00, 4402.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x: tokenizer(x['text'], padding = \"max_length\", truncation = True), batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c453ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type = 'torch', columns = ['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f2bf0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b3d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
